{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 匯入、分割資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>標題</th>\n",
       "      <th>看板名稱</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[問卦] 板上有復合成功幸福美滿的例子嗎？</td>\n",
       "      <td>Gosssiping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[新聞] 真愜意！裸上身按摩開會　亞航老闆自拍慘</td>\n",
       "      <td>Gosssiping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[問卦] 麥當勞 大蛋捲冰有賣嗎?</td>\n",
       "      <td>Gosssiping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[新聞] 走鐘獎挨轟難看、隨便！呱吉「千字文」</td>\n",
       "      <td>Gosssiping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[新聞] 15人獲文協獎章 盼促台本土文化</td>\n",
       "      <td>Gosssiping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>[新聞] 快訊／民眾黨堅持全民調　金溥聰：若只</td>\n",
       "      <td>HatePolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>[討論] 兼顧民主初選跟民調的好方法</td>\n",
       "      <td>HatePolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>[討論] 想要阿北贏要選兩次好累</td>\n",
       "      <td>HatePolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>[黑特] 藍白合到底是要演給誰看的</td>\n",
       "      <td>HatePolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>[討論] 113哪個黨最有可能輸不起</td>\n",
       "      <td>HatePolitics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           標題          看板名稱\n",
       "0       [問卦] 板上有復合成功幸福美滿的例子嗎？    Gosssiping\n",
       "2    [新聞] 真愜意！裸上身按摩開會　亞航老闆自拍慘    Gosssiping\n",
       "3           [問卦] 麥當勞 大蛋捲冰有賣嗎?    Gosssiping\n",
       "4     [新聞] 走鐘獎挨轟難看、隨便！呱吉「千字文」    Gosssiping\n",
       "5      [新聞] 15人獲文協獎章 盼促台本土文化     Gosssiping\n",
       "..                        ...           ...\n",
       "370   [新聞] 快訊／民眾黨堅持全民調　金溥聰：若只  HatePolitics\n",
       "372        [討論] 兼顧民主初選跟民調的好方法  HatePolitics\n",
       "375          [討論] 想要阿北贏要選兩次好累  HatePolitics\n",
       "379         [黑特] 藍白合到底是要演給誰看的  HatePolitics\n",
       "381        [討論] 113哪個黨最有可能輸不起  HatePolitics\n",
       "\n",
       "[1885 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ptt文章.csv\", index_col = 0)\n",
    "df = df[~df['標題'].str.contains('Re:')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "5      2\n",
       "      ..\n",
       "370    3\n",
       "372    3\n",
       "375    3\n",
       "379    3\n",
       "381    3\n",
       "Name: LABEL, Length: 1885, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LABEL'] = LabelEncoder().fit_transform(df['看板名稱'])\n",
    "df['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\CHARLIE\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.599 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>標題</th>\n",
       "      <th>看板名稱</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>標題_SEG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[問卦] 板上有復合成功幸福美滿的例子嗎？</td>\n",
       "      <td>Gosssiping</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 問卦 ]   板上 有 復 合 成功 幸福 美滿 的 例子 嗎 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[新聞] 真愜意！裸上身按摩開會　亞航老闆自拍慘</td>\n",
       "      <td>Gosssiping</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 新聞 ]   真 愜意 ！ 裸 上身 按摩 開會 　 亞航 老 闆 自 拍慘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[問卦] 麥當勞 大蛋捲冰有賣嗎?</td>\n",
       "      <td>Gosssiping</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 問卦 ]   麥當勞   大蛋 捲 冰有 賣 嗎 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[新聞] 走鐘獎挨轟難看、隨便！呱吉「千字文」</td>\n",
       "      <td>Gosssiping</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 新聞 ]   走 鐘獎 挨 轟難 看 、 隨便 ！ 呱吉 「 千字文 」</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[新聞] 15人獲文協獎章 盼促台本土文化</td>\n",
       "      <td>Gosssiping</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 新聞 ]   15 人 獲文協 獎章   盼 促台 本土 文化</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[新聞] 稱口罩國家隊賺回扣遭3大公會譴責 李鴻源</td>\n",
       "      <td>Gosssiping</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 新聞 ]   稱 口罩 國家隊 賺 回扣 遭 3 大公 會 譴責   李鴻源</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[問卦] 爸爸過世了媽媽整天上班小公主該怎辦????</td>\n",
       "      <td>Gosssiping</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 問卦 ]   爸爸 過世 了 媽媽 整天 上班 小 公主 該 怎辦 ? ? ? ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[問卦] 圓山動物園的林旺怎麼來台灣的</td>\n",
       "      <td>Gosssiping</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 問卦 ]   圓山動 物園 的 林旺 怎麼 來 台灣 的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[問卦] 以色列會變成下一個光明頂嗎？</td>\n",
       "      <td>Gosssiping</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 問卦 ]   以色列 會變 成下 一個 光明 頂 嗎 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[問卦] 現股買進 能改帳成現股賣出嗎</td>\n",
       "      <td>Gosssiping</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 問卦 ]   現股 買進   能 改帳 成現 股賣 出 嗎</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            標題        看板名稱  LABEL  \\\n",
       "0        [問卦] 板上有復合成功幸福美滿的例子嗎？  Gosssiping      2   \n",
       "2     [新聞] 真愜意！裸上身按摩開會　亞航老闆自拍慘  Gosssiping      2   \n",
       "3            [問卦] 麥當勞 大蛋捲冰有賣嗎?  Gosssiping      2   \n",
       "4      [新聞] 走鐘獎挨轟難看、隨便！呱吉「千字文」  Gosssiping      2   \n",
       "5       [新聞] 15人獲文協獎章 盼促台本土文化   Gosssiping      2   \n",
       "6    [新聞] 稱口罩國家隊賺回扣遭3大公會譴責 李鴻源  Gosssiping      2   \n",
       "7   [問卦] 爸爸過世了媽媽整天上班小公主該怎辦????  Gosssiping      2   \n",
       "8          [問卦] 圓山動物園的林旺怎麼來台灣的  Gosssiping      2   \n",
       "10         [問卦] 以色列會變成下一個光明頂嗎？  Gosssiping      2   \n",
       "11         [問卦] 現股買進 能改帳成現股賣出嗎  Gosssiping      2   \n",
       "\n",
       "                                         標題_SEG  \n",
       "0           [ 問卦 ]   板上 有 復 合 成功 幸福 美滿 的 例子 嗎 ？  \n",
       "2      [ 新聞 ]   真 愜意 ！ 裸 上身 按摩 開會 　 亞航 老 闆 自 拍慘  \n",
       "3                  [ 問卦 ]   麥當勞   大蛋 捲 冰有 賣 嗎 ?  \n",
       "4        [ 新聞 ]   走 鐘獎 挨 轟難 看 、 隨便 ！ 呱吉 「 千字文 」  \n",
       "5           [ 新聞 ]   15 人 獲文協 獎章   盼 促台 本土 文化    \n",
       "6      [ 新聞 ]   稱 口罩 國家隊 賺 回扣 遭 3 大公 會 譴責   李鴻源  \n",
       "7   [ 問卦 ]   爸爸 過世 了 媽媽 整天 上班 小 公主 該 怎辦 ? ? ? ?  \n",
       "8                [ 問卦 ]   圓山動 物園 的 林旺 怎麼 來 台灣 的  \n",
       "10               [ 問卦 ]   以色列 會變 成下 一個 光明 頂 嗎 ？  \n",
       "11              [ 問卦 ]   現股 買進   能 改帳 成現 股賣 出 嗎  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['標題_SEG'] = [jieba.lcut(sent) for sent in df['標題']]\n",
    "df['標題_SEG'] = df['標題_SEG'].apply(lambda x:' '.join(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1262,) (623,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['標題_SEG'], df['LABEL'], test_size=0.33, random_state=42)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(predicted, predicted_proba, target):\n",
    "    print('*'*50)\n",
    "    print('predicted class of first 3 test data')\n",
    "    print(predicted[:3])\n",
    "\n",
    "    print('*'*50)\n",
    "    print('predicted class proba. of first 3 test data')\n",
    "    print(predicted_proba[:3])\n",
    "\n",
    "    np.mean(predicted == target)\n",
    "    print('*'*50)\n",
    "    print('accuracy performance on test data')\n",
    "    print(np.mean(predicted == target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape using CountVectorizer\n",
      "(1262, 1000)\n",
      "test data shape using CountVectorizer\n",
      "(623, 1000)\n"
     ]
    }
   ],
   "source": [
    "# create feature vectors\n",
    "count_vect = CountVectorizer(max_features=1000) # max_features=130107\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "#prints the train data shape\n",
    "print('train data shape using CountVectorizer')\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "#prints the test data shape\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "print('test data shape using CountVectorizer')\n",
    "print(X_test_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape using TfidfVectorizer\n",
      "(1262, 1000)\n",
      "test data shape using TfidfVectorizer\n",
      "(623, 1000)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "\n",
    "print('train data shape using TfidfVectorizer')\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)\n",
    "print('test data shape using TfidfVectorizer')\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Naive Bayes classifier with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "MultinomialNB classifier with CountVectorizer\n",
      "MultinomialNB()\n",
      "**************************************************\n",
      "predicted class of first 3 test data\n",
      "[5 5 5]\n",
      "**************************************************\n",
      "predicted class proba. of first 3 test data\n",
      "[[7.97671432e-04 1.85564574e-03 5.25305409e-05 4.14088938e-05\n",
      "  2.68219075e-03 9.94570553e-01]\n",
      " [3.09494138e-01 7.35416507e-03 3.12491535e-02 6.86943843e-03\n",
      "  1.96084987e-02 6.25424607e-01]\n",
      " [4.72054153e-02 5.62236357e-02 4.82078607e-02 4.38093505e-02\n",
      "  4.75992539e-02 7.56954484e-01]]\n",
      "**************************************************\n",
      "accuracy performance on test data\n",
      "0.8250401284109149\n"
     ]
    }
   ],
   "source": [
    "# Create classifier and use count vectors\n",
    "MultinomialNB_clf = MultinomialNB()\n",
    "print('*'*50)\n",
    "print('MultinomialNB classifier with CountVectorizer')\n",
    "print(MultinomialNB_clf)\n",
    "\n",
    "# fit train data\n",
    "MultinomialNB_clf.fit(X_train_counts, y_train)\n",
    "\n",
    "# predict the class and class proba.\n",
    "predicted = MultinomialNB_clf.predict(X_test_counts)\n",
    "predicted_proba = MultinomialNB_clf.predict_proba(X_test_counts)\n",
    "\n",
    "show_result(predicted, predicted_proba, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Naive Bayes classifier with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "MultinomialNB classifier with TfidfVectorizer\n",
      "MultinomialNB()\n",
      "**************************************************\n",
      "predicted class of first 3 test data\n",
      "[5 5 5]\n",
      "**************************************************\n",
      "predicted class proba. of first 3 test data\n",
      "[[0.06641456 0.09389482 0.03436574 0.03209355 0.08780072 0.68543062]\n",
      " [0.24768708 0.11371352 0.11235325 0.07159839 0.14278431 0.31186345]\n",
      " [0.07092355 0.07390103 0.06540822 0.06167969 0.07393306 0.65415444]]\n",
      "**************************************************\n",
      "accuracy performance on test data\n",
      "0.8314606741573034\n"
     ]
    }
   ],
   "source": [
    "# Create classifier and use tf-idf vectors\n",
    "MultinomialNB_clf = MultinomialNB()\n",
    "print('*'*50)\n",
    "print('MultinomialNB classifier with TfidfVectorizer')\n",
    "print(MultinomialNB_clf)\n",
    "\n",
    "MultinomialNB_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "predicted = MultinomialNB_clf.predict(X_test_tfidf)\n",
    "predicted_proba = MultinomialNB_clf.predict_proba(X_test_tfidf)\n",
    "\n",
    "show_result(predicted, predicted_proba, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## KNN classifier with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "KNeighbors classifier with CountVectorizer\n",
      "KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
      "**************************************************\n",
      "predicted class of first 3 test data\n",
      "[5 0 5]\n",
      "**************************************************\n",
      "predicted class proba. of first 3 test data\n",
      "[[0.         0.         0.         0.         0.         1.        ]\n",
      " [0.41421356 0.         0.         0.29289322 0.         0.29289322]\n",
      " [0.         0.         0.         0.         0.         1.        ]]\n",
      "**************************************************\n",
      "accuracy performance on test data\n",
      "0.7126805778491172\n"
     ]
    }
   ],
   "source": [
    "# Create classifier and use count vectors\n",
    "KNeighborsClassifier_clf = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "print('*'*50)\n",
    "print('KNeighbors classifier with CountVectorizer')\n",
    "print(KNeighborsClassifier_clf)\n",
    "\n",
    "KNeighborsClassifier_clf.fit(X_train_counts, y_train)\n",
    "\n",
    "predicted = KNeighborsClassifier_clf.predict(X_test_counts)\n",
    "predicted_proba = KNeighborsClassifier_clf.predict_proba(X_test_counts)\n",
    "\n",
    "show_result(predicted, predicted_proba, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## KNN classifier with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "KNeighbors classifier with TfidfVectorizer\n",
      "KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
      "**************************************************\n",
      "predicted class of first 3 test data\n",
      "[5 0 5]\n",
      "**************************************************\n",
      "predicted class proba. of first 3 test data\n",
      "[[0.         0.2959052  0.         0.         0.         0.7040948 ]\n",
      " [0.34390499 0.         0.         0.         0.33095939 0.32513562]\n",
      " [0.         0.         0.         0.         0.         1.        ]]\n",
      "**************************************************\n",
      "accuracy performance on test data\n",
      "0.6388443017656501\n"
     ]
    }
   ],
   "source": [
    "# Create classifier and use tf-idf vectors\n",
    "KNeighborsClassifier_clf = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "print('*'*50)\n",
    "print('KNeighbors classifier with TfidfVectorizer')\n",
    "print(KNeighborsClassifier_clf)\n",
    "\n",
    "KNeighborsClassifier_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "predicted = KNeighborsClassifier_clf.predict(X_test_tfidf)\n",
    "predicted_proba = KNeighborsClassifier_clf.predict_proba(X_test_tfidf)\n",
    "\n",
    "show_result(predicted, predicted_proba, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## SVM classifier with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "SVM classifier with CountVectorizer\n",
      "SVC(probability=True)\n",
      "**************************************************\n",
      "predicted class of first 3 test data\n",
      "[5 5 5]\n",
      "**************************************************\n",
      "predicted class proba. of first 3 test data\n",
      "[[0.02551504 0.02179138 0.00830757 0.00683324 0.03439352 0.90315923]\n",
      " [0.09546779 0.00743315 0.06511505 0.01403252 0.0074876  0.81046389]\n",
      " [0.00274804 0.02995261 0.00422909 0.0025458  0.00129117 0.95923329]]\n",
      "**************************************************\n",
      "accuracy performance on test data\n",
      "0.8298555377207063\n"
     ]
    }
   ],
   "source": [
    "# Create classifier and use count vectors\n",
    "SVC_clf = SVC(probability=True)\n",
    "print('*'*50)\n",
    "print('SVM classifier with CountVectorizer')\n",
    "print(SVC_clf)\n",
    "\n",
    "# fit train data\n",
    "SVC_clf.fit(X_train_counts, y_train)\n",
    "\n",
    "# predict the class and class proba.\n",
    "predicted = SVC_clf.predict(X_test_counts)\n",
    "predicted_proba = SVC_clf.predict_proba(X_test_counts)\n",
    "\n",
    "print('*'*50)\n",
    "print('predicted class of first 3 test data')\n",
    "print(predicted[:3])\n",
    "\n",
    "print('*'*50)\n",
    "print('predicted class proba. of first 3 test data')\n",
    "print(predicted_proba[:3])\n",
    "\n",
    "np.mean(predicted == y_test)\n",
    "print('*'*50)\n",
    "print('accuracy performance on test data')\n",
    "print(np.mean(predicted == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## SVM classifier with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "SVM classifier with TfidfVectorizer\n",
      "SVC(probability=True)\n",
      "**************************************************\n",
      "predicted class of first 3 test data\n",
      "[5 5 5]\n",
      "**************************************************\n",
      "predicted class proba. of first 3 test data\n",
      "[[1.08837254e-02 3.15268795e-02 7.59456981e-03 4.63304754e-03\n",
      "  1.96354517e-02 9.25726326e-01]\n",
      " [1.71602207e-01 1.67527760e-02 6.21936426e-02 1.65607201e-02\n",
      "  1.63202163e-02 7.16570438e-01]\n",
      " [1.20135407e-04 9.65147686e-04 1.17765853e-03 3.76024504e-04\n",
      "  4.57089325e-04 9.96903945e-01]]\n",
      "**************************************************\n",
      "accuracy performance on test data\n",
      "0.8507223113964687\n"
     ]
    }
   ],
   "source": [
    "# Create classifier and use tf-idf vectors\n",
    "SVC_clf = SVC(probability=True)\n",
    "print('*'*50)\n",
    "print('SVM classifier with TfidfVectorizer')\n",
    "print(SVC_clf)\n",
    "\n",
    "SVC_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "predicted = SVC_clf.predict(X_test_tfidf)\n",
    "predicted_proba = SVC_clf.predict_proba(X_test_tfidf)\n",
    "\n",
    "print('*'*50)\n",
    "print('predicted class of first 3 test data')\n",
    "print(predicted[:3])\n",
    "\n",
    "print('*'*50)\n",
    "print('predicted class proba. of first 3 test data')\n",
    "print(predicted_proba[:3])\n",
    "\n",
    "np.mean(predicted == y_test)\n",
    "print('*'*50)\n",
    "print('accuracy performance on test data')\n",
    "print(np.mean(predicted == y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
